{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Work Trial - Stefan Heimersheim\n",
        "\n",
        "## Instructions\n",
        "- [ ] Save a copy of this Colab notebook to your own drive  (File > Save a copy in Drive)\n",
        "  - [ ] Update the sharing settings to “anyone with the link can comment.\"\n",
        "- [ ] Create a separate Google doc to present your results and take notes, while completing the tasks in your copy of the Colab notebook.\n",
        "  - [ ] Update the sharing settings to “anyone with the link can comment.\"\n",
        "- [ ] Set a timer and start investigating. Do not spend more than 3 hours on this task. State the time spent on this work trial at the top of your Google doc.\n",
        "- [ ] Submit both links in the MARS application."
      ],
      "metadata": {
        "id": "bVQ579SpQJU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "\n",
        "This is a setting from one of my previous mentoring groups. We were investigating a variation of the model of \"Compressed Computation\" in [Braun et al. 2025](https://arxiv.org/abs/2501.14926) (section 3.2, no need to read).\n",
        "The paper investigated a model that was able to learn 100 ReLU functions (labels) despite having only 50 neurons (actual ReLUs), when the inputs were sparse.\n",
        "\n",
        "We generalized the setting and looked at non-sparse inputs. We want to see what the model learns if there is no sparsity. You will later see (Part 2) that this model _still_ does better than we naively expected. The naive expectation was that the MLP layer will simply ignore half of the features, and perfectly represent the other half. However, we found that, if the inputs are dense, the model achieves a lower loss than this (naive) model.\n",
        "\n",
        "In this task I provide you with the trained model, and ask you to investigate what it's doing. Which features is it representing, what is it doing with the other ones, etc. Ultimately we want to figure out what \"trick\" the model is using to perform better than our naive expectation.\n",
        "\n",
        "I do not expect you to conclude this investigation as part of the work trial. Instead consider this as a first step where you start the investigation, obtain some results, and present them to me (imagine sending a couple of Slack messages, or presenting your results at the next mentoring call)."
      ],
      "metadata": {
        "id": "N_Qa_Vfr_xGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup code (imports)"
      ],
      "metadata": {
        "id": "R88KTqnJ78Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor, nn"
      ],
      "metadata": {
        "id": "ihGCQpCm78T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model & training code\n",
        "\n",
        "The following code contains a mostly-standard MLP (but **without biases**) with a skip connection, i.e. a residual network. If you're familiar with transformers, this looks basically like a 1-layer transformer (without attention, and without the sequence dimension).\n",
        "\n",
        "```\n",
        "    x ∈ R^(batch x n_features)\n",
        "         |\n",
        "         v\n",
        "    +----------+\n",
        "    |   W_E    |  Embedding matrix (fixed)\n",
        "    +----------+\n",
        "         |\n",
        "         v\n",
        "    residual ∈ R^(batch x d_embed)\n",
        "         |\n",
        "         |------------+\n",
        "         v            |\n",
        "    +----------+      |\n",
        "    |   W_in   |      |  MLP input weights (trainable)\n",
        "    +----------+      |\n",
        "         |            |\n",
        "         v            |\n",
        "    pre_act ∈ R^(batch x d_mlp)\n",
        "         |            |\n",
        "         v            |\n",
        "    +----------+      |\n",
        "    |   ReLU   |      |  ReLU activation\n",
        "    +----------+      |\n",
        "         |            |\n",
        "         v            |\n",
        "    post_act ∈ R^(batch x d_mlp)\n",
        "         |            |\n",
        "         v            |\n",
        "    +----------+      |\n",
        "    |  W_out   |      |  MLP output weights (trainable)\n",
        "    +----------+      |\n",
        "         |            |\n",
        "         v            |\n",
        "    mlp_out ∈ R^(batch x d_embed)\n",
        "         |            |\n",
        "         +<-----------+\n",
        "         |\n",
        "         v\n",
        "    residual ∈ R^(batch x d_embed)\n",
        "         |\n",
        "         v\n",
        "    +----------+\n",
        "    |   W_E.T  |  Unembedding matrix (fixed)\n",
        "    +----------+\n",
        "         |\n",
        "         v\n",
        "    out ∈ R^(batch x n_features)\n",
        "```"
      ],
      "metadata": {
        "id": "d8VdKqClzbEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and training code\n",
        "\n",
        "The model code here should match the description above.\n",
        "\n",
        "You don't need to read the training code."
      ],
      "metadata": {
        "id": "gTIh50kEAGJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration for the ResidualMLP model and training.\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    n_features: int = 100\n",
        "    d_embed: int = 1000\n",
        "    d_mlp: int = 50\n",
        "    # Training parameters\n",
        "    batch_size: int = 2048\n",
        "    steps: int = 1_000\n",
        "    lr: float = 3e-3\n",
        "    print_freq: int = 50\n",
        "\n",
        "\n",
        "class ResidualMLPModel(nn.Module):\n",
        "    \"\"\"A simple residual MLP model with fixed embeddings and one layer.\n",
        "\n",
        "    Note that the model has no biases.\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        n_features, d_embed, d_mlp = config.n_features, config.d_embed, config.d_mlp\n",
        "        # The embedding vectors are random unit vectors\n",
        "        W_E = torch.randn(n_features, d_embed)\n",
        "        W_E = F.normalize(W_E, dim=1)\n",
        "        self.register_buffer(\"W_E\", W_E)\n",
        "\n",
        "        # The MLP weights are trained\n",
        "        self.W_in = nn.Parameter(torch.empty(d_embed, d_mlp))\n",
        "        self.W_out = nn.Parameter(torch.empty(d_mlp, d_embed))\n",
        "        nn.init.xavier_normal_(self.W_in)\n",
        "        nn.init.xavier_normal_(self.W_out)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        residual = einops.einsum(x, self.W_E, \"batch n_features, n_features d_embed -> batch d_embed\")\n",
        "        pre_act = einops.einsum(residual, self.W_in, \"batch d_embed, d_embed d_mlp -> batch d_mlp\")\n",
        "        post_act = F.relu(pre_act)\n",
        "        mlp_out = einops.einsum(post_act, self.W_out, \"batch d_mlp, d_mlp d_embed -> batch d_embed\")\n",
        "        residual = residual + mlp_out\n",
        "        out = einops.einsum(residual, self.W_E, \"batch d_embed, n_features d_embed -> batch n_features\")\n",
        "        return out\n",
        "\n",
        "\n",
        "class UniformFeatureDataset:\n",
        "    \"\"\"Dataset of uniformly distributed features.\n",
        "\n",
        "    The inputs X (batch x n_features) are uniformly distributed in the range [-1, 1]. The labels Y (batch x n_features) are X + ReLU(X).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        self.n_features = config.n_features\n",
        "\n",
        "    def generate_batch(self, batch_size: int, resid: bool = True) -> tuple[Tensor, Tensor]:\n",
        "        batch = 2 * torch.rand((batch_size, self.n_features)) - 1\n",
        "        labels = F.relu(batch) + batch\n",
        "        return batch, labels\n",
        "\n",
        "\n",
        "def train(config: Config, model: ResidualMLPModel, dataset: UniformFeatureDataset) -> None:\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=0.01)\n",
        "    dataset = UniformFeatureDataset(config)\n",
        "\n",
        "    for step in range(config.steps):\n",
        "        batch, labels = dataset.generate_batch(config.batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch)\n",
        "        loss = ((outputs - labels) ** 2).mean(dim=(0, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % config.print_freq == 0 or step == config.steps - 1:\n",
        "            print(f\"Step {step} loss: {loss.item():.2e}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model: ResidualMLPModel, dataset: UniformFeatureDataset, batch_size: int = 10_000) -> float:\n",
        "    with torch.no_grad():\n",
        "        batch, labels = dataset.generate_batch(batch_size)\n",
        "        outputs = model(batch)\n",
        "        loss = ((outputs - labels) ** 2).mean(dim=(0, 1)).item()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0PVf1JvbzJZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "The following cell runs the training code (should take less than a minute, you can just use a CPU).\n",
        "\n",
        "It should automatically load the model the 2nd time you run this cell, otherwise adjust the code below."
      ],
      "metadata": {
        "id": "_6dHYlxdz3c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(steps=500, batch_size=2048)\n",
        "\n",
        "model_path = Path(\"model.pkl\")\n",
        "if not model_path.exists():\n",
        "    model = ResidualMLPModel(config)\n",
        "    dataset = UniformFeatureDataset(config)\n",
        "    train(config, model, dataset)\n",
        "    with open(model_path, \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "else:\n",
        "    with open(model_path, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "        dataset = UniformFeatureDataset(config)\n",
        "\n",
        "print(\"Trained model loss:\", evaluate(model, dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRzPEP5hzQf2",
        "outputId": "b96b3d7e-3a2a-484d-d331-7d5a58a1a703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 loss: 2.01e-01\n",
            "Step 50 loss: 6.99e-02\n",
            "Step 100 loss: 6.27e-02\n",
            "Step 150 loss: 6.20e-02\n",
            "Step 200 loss: 6.09e-02\n",
            "Step 250 loss: 6.00e-02\n",
            "Step 300 loss: 5.86e-02\n",
            "Step 350 loss: 5.80e-02\n",
            "Step 400 loss: 5.69e-02\n",
            "Step 450 loss: 5.61e-02\n",
            "Step 499 loss: 5.56e-02\n",
            "Trained model loss: 0.05555826053023338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task (part 1)\n",
        "\n",
        "This model has only 50 neurons, but we trained it on 100 input features. We want to see what the model has learned.\n",
        "\n",
        "In this exercise I want to test how well you can iterate on results and find good ways to extract and present information. The suggestions below are what I might say during a mentoring call. You don't have to stick to them exactly, and you don't have to stop there!\n",
        "\n",
        "> I think we should start by measuring the loss per feature (for the different features), can you plot this? And can you plot the input-output response for each feature (where input feature = output feature), maybe in isolation (only that feature non-zero) or together with other features active."
      ],
      "metadata": {
        "id": "ElHGUGx00IDh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wb0XsSBz1z_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AGPTFYMe74KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example code how you might interact with the model\n",
        "batch_size = 1\n",
        "batch = torch.zeros(batch_size, config.n_features)\n",
        "batch[:, 42] = 1\n",
        "label = F.relu(batch) + batch\n",
        "out = model(batch).detach()\n",
        "plt.scatter(np.arange(config.n_features), out[0], label=\"output\")\n",
        "plt.scatter(np.arange(config.n_features), label[0], label=\"label\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "5CNVrHa33xN_",
        "outputId": "c2c098dd-c7d3-4768-8b7a-82ad85fa67bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZ7CRMBo3xRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9y-lpY5v3xUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task (part 2)"
      ],
      "metadata": {
        "id": "Z7GU3N6D12-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSolution(nn.Module):\n",
        "    \"\"\"A simple ResidualMLP model with no embeddings (W_E = I) and identity MLP weights\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.W_in = nn.Parameter(torch.eye(config.n_features, config.d_mlp))\n",
        "        self.W_out = nn.Parameter(torch.eye(config.d_mlp, config.n_features))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        pre_act = einops.einsum(x, self.W_in, \"batch n_features, n_features d_mlp -> batch d_mlp\")\n",
        "        post_act = F.relu(pre_act)\n",
        "        out = einops.einsum(post_act, self.W_out, \"batch d_mlp, d_mlp n_features -> batch n_features\")\n",
        "        return out + x\n",
        "\n",
        "\n",
        "naive_model = NaiveSolution(config)\n",
        "print(\"Naive model loss:\", evaluate(naive_model, dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yTeuPG7yZM",
        "outputId": "89b0711b-1a01-49ae-e1d0-5bf247303da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive model loss: 0.08340801298618317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The model we trained appears to achieve a better loss than the naive solution (representing just half the features, which should get a loss of 0.0833). How does it do that? What is it doing?\n",
        "\n",
        "> I would generally like to check how the model loss scales with number of active features. (In the training dataset all features were active, but we can just run the model with all features except for some set to 0.) Can you plot the \"average loss per feature\" (that is just loss divided by fraction of active features), as a function of number of active features?\n",
        "\n",
        "> And after that, maybe check if there's any pattern in the input-output response of the \"cross-terms\", i.e. where input feature != output feature?"
      ],
      "metadata": {
        "id": "TEIFTV5D70Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KeVvcZOW12fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x95KKAyE1xuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJ65_M9c8FF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4An9sz4j8FIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}